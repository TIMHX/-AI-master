{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongxing/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function                  # Allows for python3 printing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Sonnets.txt\"\n",
    "#read the file and make all chracaters lowercase\n",
    "text = open(filename).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 107701\n",
      "total chars: 63\n",
      "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~']\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "print('text length:', len(text))    # this prints the length of the text \n",
    "\n",
    "chars = sorted(list(set(text)))    # sorted():Return a new list containing all items from the iterable in ascending order.\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "##This should print 38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 encoding and decoding dictionaries\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 cut corpus into equal length sequences\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])               \n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)   #generate zeros with size[number of sentences,40,38]\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool) #generate zeros with size[number of sentences,38]\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, input_shape=(x.shape[1], x.shape[2])))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 5s 153us/step - loss: 2.8954\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 5s 149us/step - loss: 2.4846\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 5s 138us/step - loss: 2.3284\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 5s 138us/step - loss: 2.2450\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 5s 142us/step - loss: 2.1883\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 5s 149us/step - loss: 2.1427\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 5s 153us/step - loss: 2.0994\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 6s 154us/step - loss: 2.0603\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 5s 143us/step - loss: 2.0284\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 5s 138us/step - loss: 1.9966\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "thau fart the wish the wist thou have thou maye the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 5s 135us/step - loss: 1.9667\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 5s 133us/step - loss: 1.9402\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 5s 135us/step - loss: 1.9129\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 5s 133us/step - loss: 1.8905\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 5s 135us/step - loss: 1.8699\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 5s 142us/step - loss: 1.8469\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 5s 149us/step - loss: 1.8258\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 6s 156us/step - loss: 1.8071\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 5s 144us/step - loss: 1.7874\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 5s 134us/step - loss: 1.7666\n",
      "\n",
      "Iteration 2\n",
      "h i seave thee in lied,\n",
      "and the wist the sunes and thee i so the compings with thee in the sich and me tome to thee in forment thee,\n",
      "\n",
      " thin shall seall then thee so foor have se prove thoughts thee in the some to thee in forment me beare,\n",
      "when in the compicance of the sonderthe doth has is thee in farth stere thee in the with thee in ghees mo have the world has with thee in love so preading hise w\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 5s 134us/step - loss: 1.7508\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 5s 131us/step - loss: 1.7337\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 5s 130us/step - loss: 1.7169\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 5s 133us/step - loss: 1.7013\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 5s 127us/step - loss: 1.6818\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 5s 127us/step - loss: 1.6703\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 5s 127us/step - loss: 1.6513\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 5s 131us/step - loss: 1.6394\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 5s 129us/step - loss: 1.6267\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.6137\n",
      "\n",
      "Iteration 3\n",
      "re thee thou his it stoll stale siel compare the wiel for is love to bear,\n",
      "when i so lece and the efure soor and that is the will with the rearent ore suene for the remperting the will by sich thee in the will i seavers to the racking the with the sine,\n",
      "and to her that thou hate by greast that you doun thee the withon my somp tain as my live the seare to my seare that is they the will by the will \n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 5s 129us/step - loss: 1.5996\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.5869\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.5750\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.5614\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.5529\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.5370\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.5255\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 5s 126us/step - loss: 1.5161\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 5s 129us/step - loss: 1.5065\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.4947\n",
      "\n",
      "Iteration 4\n",
      "or it so me to dot by the world there a dote beat in your doun in the with not the suren when thou grow far thy self the wist thou me dos my heart to me thy beagh shathe be of the dist an the will the wind,\n",
      "when it suppenters and the beare the wield the with the willd that thou doth thy self-dost to me the conf-ampree,\n",
      "when in thy self the trie,\n",
      "the computiou are and reauty ore thee i so thy sourd\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 4s 121us/step - loss: 1.4869\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 4s 120us/step - loss: 1.4769\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 5s 130us/step - loss: 1.4651\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.4601\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 5s 127us/step - loss: 1.4486\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 4s 125us/step - loss: 1.4412\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 123us/step - loss: 1.4325\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.4256\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.4198\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.4131\n",
      "\n",
      "Iteration 5\n",
      "ele thie is my soof of the content,\n",
      "then the ser berund come) thou sight, when in the wish whethe reake thee in geadent ond erese for not the chack'd riee,\n",
      "  then be the ere dore stele are the sellld comering thy sweet store stare share sweet thee, not the sen be my sumpertise in myes not comer's glows\n",
      "with the erven com thee,\n",
      "the concoud, when i so te grade\n",
      "the contren the etextus in will the ere\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 4s 123us/step - loss: 1.4026\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 5s 126us/step - loss: 1.3995\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 5s 136us/step - loss: 1.3935\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 5s 128us/step - loss: 1.3866\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 5s 126us/step - loss: 1.3819\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.3758\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.3679\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.3624\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 4s 121us/step - loss: 1.3564\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.3573\n",
      "\n",
      "Iteration 6\n",
      "are,\n",
      "  this will the erve thou art that i may thes thine that peadich in my sour in\n",
      "which my deast:\n",
      "bod my love the brase born realy part, and the eruse that is the wisted faris, the beauty, and then the reaking for thee thine that me and the beath dost to my bearts for as the erends for wiss and lovers and rome to gus, whe in the beauty stire\n",
      "shall love and love and eauty loven thee might though \n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.3502\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.3430\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.3423\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 4s 124us/step - loss: 1.3357\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 4s 125us/step - loss: 1.3328\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.3300\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.3212\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.3235\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.3228\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 115us/step - loss: 1.3157\n",
      "\n",
      "Iteration 7\n",
      "that is the with do the with the will will tigh sead,\n",
      "when i have sweet shant stole to beauty my vorsed ma home i ful will my sele thee so my will on the wall for thee this in theee when is this still sich printed have mo eicele that the warth us thee, frow far in theee with this whee in the wisce of oundone samily hess,\n",
      "what is the ente thee prove anof ese, and theref love,\n",
      "thee sor of that i mas\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.3119\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.3106\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.3069\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.2999\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.2973\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.2965\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 116us/step - loss: 1.2932\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.2880\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.2841\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 121us/step - loss: 1.2930\n",
      "\n",
      "Iteration 8\n",
      ",\n",
      "for the sorer which thy self the provice,\n",
      "this ot thee artion all i my heart to my selfour with the wish on the foust for thee this and thought,\n",
      "which love to thee in love sacksted;\n",
      "the comprest the comport, thou mast of the the confaul they beauty have will be will the wind,\n",
      "  then fort with this, the excxle\n",
      "then to shall wile in the with noter fares, sell on the warly all the wist thy heart ho\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 4s 119us/step - loss: 1.2808\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 5s 128us/step - loss: 1.2827\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.2796\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.2831\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.2760\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 5s 127us/step - loss: 1.2722\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 118us/step - loss: 1.2705\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 4s 122us/step - loss: 1.2659\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 4s 120us/step - loss: 1.2663\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 120us/step - loss: 1.2583\n",
      "\n",
      "Iteration 9\n",
      "hines in the will in mentor one trief paid, though to thy confrim thene ore brace shougs of you i woul tory, and in thes in hath no manuth sooks the widse whill for thee i so the ere love a doth whel beauty same in thee.\n",
      "\n",
      "cxiv\n",
      "\n",
      "should the will for well ore beauty, and the etixts stor mash ind love sweet beauty, and the etixts stor prove\n",
      "that you woll i frome\n",
      "that sexpies,\n",
      "  the will the wing,\n",
      "when\n",
      "\n",
      "Epoch 1/10\n",
      "35887/35887 [==============================] - 4s 121us/step - loss: 1.2650\n",
      "Epoch 2/10\n",
      "35887/35887 [==============================] - 5s 128us/step - loss: 1.2628\n",
      "Epoch 3/10\n",
      "35887/35887 [==============================] - 4s 117us/step - loss: 1.2554\n",
      "Epoch 4/10\n",
      "35887/35887 [==============================] - 4s 121us/step - loss: 1.2499\n",
      "Epoch 5/10\n",
      "35887/35887 [==============================] - 4s 110us/step - loss: 1.2536\n",
      "Epoch 6/10\n",
      "35887/35887 [==============================] - 4s 112us/step - loss: 1.2474\n",
      "Epoch 7/10\n",
      "35887/35887 [==============================] - 4s 108us/step - loss: 1.2486\n",
      "Epoch 8/10\n",
      "35887/35887 [==============================] - 4s 112us/step - loss: 1.2411\n",
      "Epoch 9/10\n",
      "35887/35887 [==============================] - 4s 109us/step - loss: 1.2509\n",
      "Epoch 10/10\n",
      "35887/35887 [==============================] - 4s 113us/step - loss: 1.2476\n",
      "\n",
      "Iteration 10\n",
      "e mad pabjed distot on the hamus so, and the with the wills me have theee is in my silf love stales\n",
      "                                                                                                                                                                                                                                                                                                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 11):\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=10)\n",
    "    \n",
    "# generating text\n",
    "    print('\\nIteration', iteration)\n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]      #predict using model, generating a matrix of softmax\n",
    "        next_index = np.argmax(preds)                    #we want the index with highest probability \n",
    "        next_char = indices_char[next_index]             #convert number back to character using the dictionary\n",
    "        sentence = sentence[1:] + next_char              #append the character predicted to the sentence (start from the second character)\n",
    "\n",
    "        sys.stdout.write(next_char)                \n",
    "        sys.stdout.flush()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
